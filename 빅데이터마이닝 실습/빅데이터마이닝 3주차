{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP9mHZAyi6Wd81xG1n+lcou"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np\n","\n","X = np.array([1,2,3]).reshape(-1,1)\n","y = np.array([2,3,5])\n","\n","X_with_intercept = np.c_[np.ones(X.shape[0]),X]\n","\n","w = np.linalg.inv(X_with_intercept.T.dot(X_with_intercept)).dot(X_with_intercept.T).dot(y)\n","\n","intercept = w[0]\n","slope = w[1]\n","\n","print('intercept:', intercept)\n","print('slope:', slope)\n","\n","y_pred = X_with_intercept.dot(w)\n","print('prediction:', y_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ngJTfmNr_mCh","executionInfo":{"status":"ok","timestamp":1742347699867,"user_tz":-540,"elapsed":24,"user":{"displayName":"이창수","userId":"02759287954653446121"}},"outputId":"6f047174-2cba-4703-8a25-175138e1daff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["intercept: 0.3333333333333304\n","slope: 1.5\n","prediction: [1.83333333 3.33333333 4.83333333]\n"]}]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.linear_model import LinearRegression\n","\n","X = np.array([1,2,3]).reshape(-1,1)\n","y = np.array([2,3,5])\n","\n","model = LinearRegression()\n","model.fit(X,y)\n","\n","\n","print('intercept:', intercept)\n","print('slope:', slope)\n","\n","y_pred = X_with_intercept.dot(w)\n","print('prediction:', y_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cqtfUn2GCbPu","executionInfo":{"status":"ok","timestamp":1742348122463,"user_tz":-540,"elapsed":5299,"user":{"displayName":"이창수","userId":"02759287954653446121"}},"outputId":"293bcc6a-ba3f-4bdf-aa04-5cd9b0b5052c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["intercept: 0.3333333333333304\n","slope: 1.5\n","prediction: [1.83333333 3.33333333 4.83333333]\n"]}]},{"cell_type":"code","source":["import numpy as np\n","\n","class LinearRegressionGD:\n","    def __init__(self, fit_intercept=True, copy_X=True,\n","                 eta0=0.001, epochs=1000, batch_size=1,\n","                 weight_decay=0.9, shuffle=True):\n","        self.fit_intercept = fit_intercept  # intercept 여부\n","        self.copy_X = copy_X  # 데이터를 복사할지 여부\n","        self._eta0 = eta0  # 초기 학습률\n","        self._epochs = epochs  # 학습할 epoch 수\n","\n","        self._cost_history = []  # 비용 기록을 위한 리스트\n","        self._coef = None  # 회귀 계수\n","        self._intercept = None  # 절편\n","        self._new_X = None  # 데이터를 저장할 변수\n","        self._w_history = None  # 가중치 업데이트 기록\n","        self._weight_decay = weight_decay  # 학습률 감소율\n","        self._batch_size = batch_size  # 배치 크기\n","        self._is_SGD = shuffle  # 데이터를 섞을지 여부\n","\n","    def gradient(self, X, y, theta):\n","        # 경사하강법을 위한 기울기 계산\n","        return ######## 코드 작성 ##########\n","\n","    def fit(self, X, y):\n","        # 학습을 시작하는 함수\n","        self._new_X = np.array(X)  # X 데이터를 numpy 배열로 변환하여 저장\n","        y = y.reshape(-1, 1)  # y 데이터를 열 벡터로 변환\n","        if self.fit_intercept:  # intercept 추가 여부 확인\n","            intercept_vector = ######## 코드 작성 ##########  # 1로만 구성된 벡터\n","            self._new_X = np.concatenate((intercept_vector, self._new_X), axis=1)  # X에 상수항 추가\n","\n","        theta_init = np.random.normal(0, 1, self._new_X.shape[1])  # 초기 theta 값 설정 (정규분포)\n","        self._w_history = [theta_init]  # 가중치 기록 초기화\n","        self._cost_history = [self.cost(self.hypothesis_function(self._new_X, theta_init), y)]  # 비용 기록 초기화\n","\n","        theta = theta_init  # 초기 theta로 시작\n","\n","        for epoch in range(self._epochs):  # 지정된 epoch 횟수만큼 학습 실행\n","            X_copy, y_copy = np.copy(self._new_X), np.copy(y)  # X와 y를 복사하여 수정하지 않도록 함\n","\n","            if self._is_SGD:  # SGD(확률적 경사 하강법) 적용 여부\n","                indices = np.arange(len(X_copy))  # X_copy의 인덱스 생성\n","                ######## 코드 작성 ##########  # 인덱스를 무작위로 섞음\n","                X_copy, y_copy = X_copy[indices], y_copy[indices]  # X와 y를 섞은 인덱스로 재배치\n","\n","            num_batches = len(X_copy) // self._batch_size  # 배치의 개수 계산\n","\n","            for batch_count in range(num_batches):  # 배치마다 학습 실행\n","                start = ######## 코드 작성 ##########  # 배치의 시작 인덱스\n","                end = ######## 코드 작성 ##########  # 배치의 끝 인덱스\n","\n","                X_batch = X_copy[start:end]  # 배치 크기에 맞는 X 데이터 추출\n","                y_batch = y_copy[start:end]  # 배치 크기에 맞는 y 데이터 추출\n","\n","                gradient = self.gradient(X_batch, y_batch, theta).flatten()  # 배치에 대한 기울기 계산\n","                theta = theta - self._eta0 * gradient  # 경사하강법으로 theta 업데이트\n","\n","            if epoch % 100 == 0:  # 100번째 epoch마다 가중치 기록과 비용 기록 추가\n","                self._w_history.append(theta)\n","                cost = self.cost(self.hypothesis_function(self._new_X, theta), y)  # 현재 모델의 비용 계산\n","                self._cost_history.append(cost)  # 비용 기록에 추가\n","\n","            self._eta0 *= self._weight_decay  # 학습률을 weight_decay 비율로 감소시킴\n","\n","        if self.fit_intercept:  # intercept이 존재하면 분리하여 저장\n","            self._intercept = theta[0]\n","            self._coef = theta[1:]\n","        else:  # intercept이 없으면 theta 그대로 사용\n","            self._coef = theta\n","\n","    def cost(self, h, y):\n","        # 비용 함수 계산 (평균 제곱 오차)\n","        return 1 / (2 * len(y)) * np.sum((h - y).flatten() ** 2)\n","\n","    def hypothesis_function(self, X, theta):\n","        # 예측 함수 (모델의 가설)\n","        return X.dot(theta).reshape(-1, 1)\n","\n","    def predict(self, X):\n","        # 주어진 X에 대해 예측을 수행하는 함수\n","        test_X = np.array(X)\n","\n","        if self.fit_intercept:  # intercept 추가 여부 확인\n","            intercept_vector = np.ones([len(test_X), 1])  # 1로만 구성된 벡터\n","            test_X = np.concatenate((intercept_vector, test_X), axis=1)  # X에 상수항 추가\n","            weights = np.concatenate(([self._intercept], self._coef), axis=0)  # weights에 intercept와 coef 결합\n","        else:\n","            weights = self._coef  # intercept 없이 coef만 사용\n","\n","        return ######## 코드 작성 ##########  # 예측값 계산\n","\n","    @property\n","    def coef(self):\n","        # 회귀 계수를 반환하는 프로퍼티\n","        return self._coef\n","\n","    @property\n","    def intercept(self):\n","        # 절편을 반환하는 프로퍼티\n","        return self._intercept\n","\n","    @property\n","    def weights_history(self):\n","        # 가중치 업데이트 기록을 반환하는 프로퍼티\n","        return np.array(self._w_history)\n","\n","    @property\n","    def cost_history(self):\n","        # 비용 기록을 반환하는 프로퍼티\n","        return self._cost_history"],"metadata":{"id":"Xy1wEXW6JBIm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!wget https://raw.githubusercontent.com/dankook-sw/DataMining/refs/heads/main/ch08/train.csv"],"metadata":{"id":"Ha6sqn42KPrj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!wget https://raw.githubusercontent.com/dankook-sw/DataMining/refs/heads/main/ch08/test.csv"],"metadata":{"id":"nNaDGxrlKTTu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls /content/"],"metadata":{"id":"aifUvom4KVbk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","df = pd.read_csv(\"/content/train.csv\")\n","\n","X = df[\"x\"].values.reshape(-1,1)\n","y = df[\"y\"].values\n","\n","epoch = 10\n","eta = 0.01\n","gd_lr = LinearRegressionGD(eta0=eta, epochs=epoch, batch_size=1, shuffle=False)\n","bgd_lr = LinearRegressionGD(eta0=eta, epochs=epoch, batch_size=len(X), shuffle=False)\n","sgd_lr = LinearRegressionGD(eta0=eta, epochs=epoch, batch_size=1, shuffle=True)\n","msgd_lr = LinearRegressionGD(eta0=eta, epochs=epoch, batch_size=20, shuffle=True)"],"metadata":{"id":"zRIobC8aKYIv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gd_lr.fit(X, y)\n","bgd_lr.fit(X, y)\n","sgd_lr.fit(X, y)\n","msgd_lr.fit(X, y)"],"metadata":{"id":"BR7bviqSKbLC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","plt.plot(range(len(gd_lr.cost_history)), gd_lr.cost_history, c=\"r\")\n","plt.plot(range(len(bgd_lr.cost_history)), bgd_lr.cost_history, c=\"y\")\n","plt.plot(range(len(sgd_lr.cost_history)), sgd_lr.cost_history, c=\"g\")\n","plt.plot(range(len(msgd_lr.cost_history)), msgd_lr.cost_history, c=\"b\")"],"metadata":{"id":"2LJHgsVzKgnZ"},"execution_count":null,"outputs":[]}]}